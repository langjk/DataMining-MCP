# test_complete_workflow.py
# æµ‹è¯•å®Œæ•´çš„åˆ†æžå·¥ä½œæµç¨‹

import json
from gpt_dispatcher import dispatch_gpt_response

def simulate_gpt_analysis_response(tool_result_data):
    """æ¨¡æ‹ŸGPTæŽ¥æ”¶å·¥å…·ç»“æžœåŽçš„åˆ†æžå“åº”"""
    
    # ä»Žå·¥å…·ç»“æžœä¸­æå–å…³é”®ä¿¡æ¯
    analysis_results = tool_result_data.get("analysis_results", {})
    file_metadata = tool_result_data.get("file_metadata", {})
    analysis_type = tool_result_data.get("analysis_type", "")
    
    # æ¨¡æ‹ŸGPTçš„åˆ†æžæ€»ç»“
    key_findings = []
    overall_assessment = ""
    recommendations = []
    
    if analysis_type == "stability":
        # ç¨³å®šæ€§åˆ†æžæ€»ç»“
        stable_metrics = []
        for metric, data in analysis_results.items():
            rating = data.get("stability_rating", "")
            if rating == "æžç¨³å®š":
                stable_metrics.append(metric)
        
        key_findings = [
            f"æ‰€æœ‰{len(analysis_results)}ä¸ªå…³é”®æŒ‡æ ‡å‡è¾¾åˆ°æžç¨³å®šçº§åˆ«",
            f"Viç”µåŽ‹è¾“å…¥ä¿æŒå®Œå…¨ç¨³å®š(ç¨³å®šæ€§æŒ‡æ•°=1.0)",
            f"æ•ˆçŽ‡æŒ‡æ ‡ç¨³å®šæ€§æŒ‡æ•°è¾¾åˆ°{analysis_results.get('æ•ˆçŽ‡', {}).get('stability_index', 0):.4f}"
        ]
        
        overall_assessment = f"ç¬¬3æ‰¹æ¬¡è®¾å¤‡åœ¨{file_metadata.get('rows', 0)}ä¸ªæµ‹è¯•ç‚¹ä¸­è¡¨çŽ°å‡ºè‰²çš„ç¨³å®šæ€§"
        
        recommendations = [
            "å½“å‰æ‰¹æ¬¡ç¨³å®šæ€§è¡¨çŽ°ä¼˜ç§€ï¼Œå¯ä»¥ä½œä¸ºæ ‡å‡†å‚è€ƒ",
            "å»ºè®®ç»§ç»­ä¿æŒå½“å‰çš„ç”Ÿäº§å·¥è‰ºå‚æ•°",
            "å¯ä»¥è€ƒè™‘é€‚å½“æé«˜æµ‹è¯•è´Ÿè½½ä»¥éªŒè¯æžé™ç¨³å®šæ€§"
        ]
    
    elif analysis_type == "comprehensive":
        # ç»¼åˆåˆ†æžæ€»ç»“
        data_quality = analysis_results.get("data_quality", {})
        key_findings = [
            f"æ•°æ®è´¨é‡è¯„çº§: {data_quality.get('quality_rating', 'æœªçŸ¥')}",
            f"å®Œæ•´æ€§: {data_quality.get('average_completeness', 0):.1f}%",
            "æ‰€æœ‰å…³é”®ç”µæ°”å‚æ•°å‡åœ¨æ­£å¸¸èŒƒå›´å†…"
        ]
        
        overall_assessment = "è®¾å¤‡è¿è¡ŒçŠ¶æ€è‰¯å¥½ï¼Œå„é¡¹æŒ‡æ ‡è¡¨çŽ°ç¨³å®š"
        recommendations = ["ç»§ç»­ç›‘æŽ§å…³é”®å‚æ•°å˜åŒ–", "å®šæœŸè¿›è¡Œç¨³å®šæ€§è¯„ä¼°"]
    
    # æž„é€ æ ‡å‡†çš„analysis_completeå“åº”
    response = {
        "action": "analysis_complete",
        "analysis_summary": {
            "data_source": f"{file_metadata.get('filename', 'æœªçŸ¥æ–‡ä»¶')} ({file_metadata.get('rows', 0)}æ¡è®°å½•)",
            "key_findings": key_findings,
            "overall_assessment": overall_assessment,
            "recommendations": recommendations
        }
    }
    
    return json.dumps(response, ensure_ascii=False)

def test_complete_workflow():
    """æµ‹è¯•å®Œæ•´çš„å·¥ä½œæµç¨‹ï¼šå·¥å…·è°ƒç”¨ -> ç»“æžœå¤„ç† -> GPTåˆ†æž"""
    print("=" * 60)
    print("æµ‹è¯•å®Œæ•´çš„åˆ†æžå·¥ä½œæµç¨‹")
    print("=" * 60)
    
    # æ­¥éª¤1: æ¨¡æ‹Ÿç”¨æˆ·è¯·æ±‚ -> GPTå·¥å…·è°ƒç”¨
    print("ðŸ”¹ æ­¥éª¤1: ç”¨æˆ·è¯·æ±‚ -> GPTå·¥å…·è°ƒç”¨")
    user_request = "åˆ†æžç¬¬3æ‰¹æ¬¡çš„ç¨³å®šæ€§"
    print(f"ç”¨æˆ·è¯·æ±‚: {user_request}")
    
    tool_call = {
        "action": "invoke_tool",
        "tool": "data_analysis",
        "args": {
            "analysis_type": "stability",
            "file_path": "./data/æµ‹è¯•æ•°æ®æ­£ï¼ˆå…¬å¼€ï¼‰/æŒ¯åŠ¨ï¼ˆå…¬å¼€ï¼‰/XXX-254-31Z01-03éšæœºæŒ¯åŠ¨è¯•éªŒï¼ˆå…¬å¼€ï¼‰.csv"
        },
        "description": "ç”¨æˆ·è¦æ±‚åˆ†æžç¬¬3æ‰¹æ¬¡çš„ç¨³å®šæ€§"
    }
    print(f"GPTå·¥å…·è°ƒç”¨: {json.dumps(tool_call, ensure_ascii=False)[:100]}...")
    
    # æ­¥éª¤2: ç³»ç»Ÿæ‰§è¡Œå·¥å…·è°ƒç”¨
    print("\nðŸ”¹ æ­¥éª¤2: ç³»ç»Ÿæ‰§è¡Œå·¥å…·è°ƒç”¨")
    try:
        tool_result = dispatch_gpt_response(json.dumps(tool_call, ensure_ascii=False))
        
        if tool_result["type"] == "tool_result":
            print("âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ!")
            tool_data = tool_result["data"]
            print(f"æ•°æ®é‡: {len(json.dumps(tool_data, ensure_ascii=False))} å­—ç¬¦")
            print(f"åˆ†æžç±»åž‹: {tool_data.get('analysis_type', '')}")
            print(f"åˆ†æžæŒ‡æ ‡æ•°: {len(tool_data.get('analysis_results', {}))}")
        else:
            print(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {tool_result.get('content', '')}")
            return False
            
    except Exception as e:
        print(f"âŒ å·¥å…·è°ƒç”¨å¼‚å¸¸: {str(e)}")
        return False
    
    # æ­¥éª¤3: æ¨¡æ‹ŸGPTåˆ†æžå·¥å…·ç»“æžœ
    print("\nðŸ”¹ æ­¥éª¤3: GPTåˆ†æžå·¥å…·ç»“æžœ")
    gpt_analysis = simulate_gpt_analysis_response(tool_data)
    print("GPTåˆ†æžå“åº”ç”ŸæˆæˆåŠŸ!")
    
    try:
        analysis_json = json.loads(gpt_analysis)
        summary = analysis_json["analysis_summary"]
        
        print(f"ðŸ“ æ•°æ®æº: {summary['data_source']}")
        print("ðŸ” å…³é”®å‘çŽ°:")
        for i, finding in enumerate(summary["key_findings"], 1):
            print(f"  {i}. {finding}")
        print(f"ðŸ“Š æ•´ä½“è¯„ä»·: {summary['overall_assessment']}")
        print("ðŸ’¡ å»ºè®®:")
        for i, rec in enumerate(summary["recommendations"], 1):
            print(f"  {i}. {rec}")
            
    except Exception as e:
        print(f"âŒ GPTåˆ†æžç»“æžœè§£æžå¤±è´¥: {str(e)}")
        return False
    
    print("\n" + "=" * 60)
    print("âœ… å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯•æˆåŠŸ!")
    print("ç”¨æˆ·ä½“éªŒ: è¯·æ±‚ -> å·¥å…·æ‰§è¡Œ -> æ™ºèƒ½åˆ†æž -> ç»“æž„åŒ–ç»“æžœ")
    print("=" * 60)
    
    return True

if __name__ == "__main__":
    test_complete_workflow()